# IstvÃ¡n VÃ¡gÃ³ Voice Cloning Project - XTTS-v2

## ðŸŽ¯ Project Goal
Fine-tune Coqui XTTS-v2 model to clone IstvÃ¡n VÃ¡gÃ³'s voice (famous Hungarian quiz show host) for building a high-quality quiz application. Target quality: ElevenLabs/Fish Audio level.

## ðŸ–¥ï¸ System Requirements
- **OS**: Windows 10/11
- **GPU**: NVIDIA RTX 4070 (12GB VRAM)
- **CUDA**: 11.8 or 12.1
- **Python**: 3.9-3.11 (3.10 recommended)
- **RAM**: 16GB+ recommended

## ðŸ“ Project Structure
```
tts-2/
â”œâ”€â”€ source_clips/          # Original audio samples (IstvÃ¡n VÃ¡gÃ³)
â”œâ”€â”€ processed_clips/       # Preprocessed audio (22050Hz, mono)
â”œâ”€â”€ source_text/          # Transcriptions (Hungarian text)
â”œâ”€â”€ dataset/              # Final training dataset
â”œâ”€â”€ checkpoints/          # Model checkpoints
â”œâ”€â”€ output/               # Generated audio samples
â”œâ”€â”€ scripts/              # Utility scripts
â””â”€â”€ configs/              # Configuration files
```

## ðŸŽ¤ Audio Requirements for Maximum Quality

### Dataset Specifications
- **Sample Rate**: 22050 Hz (for training), 24000 Hz (output)
- **Format**: WAV, mono
- **Duration per clip**: 3-15 seconds (optimal: 5-10s)
- **Total audio**: 10-30 minutes minimum (more = better)
- **Quality**: Clean, no background noise/music
- **SNR**: >20dB recommended
- **Dynamic Range**: Good variation in pitch and energy

### Text Requirements
- Accurate transcriptions in Hungarian
- Proper punctuation and diacritics (Ã¡, Ã©, Ã­, Ã³, Ã¶, Å‘, Ãº, Ã¼, Å±)
- Natural speech patterns

## ðŸš€ Setup Instructions

### 1. Environment Setup
See `scripts/setup_environment.ps1`

### 2. Data Preparation
See `scripts/prepare_dataset.py`

### 3. Training
See `scripts/train_xtts.py`

### 4. Inference
See `scripts/inference.py`

## ðŸ“Š Quality Benchmarks (Target)
- **Naturalness**: 4.5+/5.0 (MOS score)
- **Intelligibility**: 95%+ word accuracy
- **Speaker Similarity**: 4.5+/5.0
- **Prosody**: Natural Hungarian intonation
- **Latency**: <500ms for real-time applications

## ðŸ”§ Key Parameters for Quality

### Training
- Batch size: 2-4 (GPU dependent)
- Gradient accumulation: 64-126 steps
- Learning rate: 5e-6 to 1e-5
- Epochs: 15-30 (with early stopping)
- Temperature: 0.65-0.85 (inference)

### Audio Processing
- Noise reduction: Applied
- Normalization: Peak normalization + RMS leveling
- Silence trimming: Aggressive (speech only)

## ðŸ“ Version Control
Git checkpoints at:
1. Initial setup
2. Dataset preparation complete
3. Training start
4. Best checkpoint milestone
5. Final model

## ðŸŽ“ Resources
- [Coqui TTS Documentation](https://docs.coqui.ai/)
- [XTTS-v2 Paper](https://arxiv.org/abs/2309.08519)
- [Hungarian Language Guide for TTS](https://github.com/coqui-ai/TTS/discussions)

## ðŸ“„ License
This is a personal research project for educational purposes.
