"""
Load trained XTTS model and generate quiz show samples
Handles trainer checkpoint format properly
"""

import os
import sys
import torch
import torchaudio
from pathlib import Path

# Add TTS to path
try:
    from TTS.tts.configs.xtts_config import XttsConfig
    from TTS.tts.models.xtts import Xtts
except ImportError as e:
    print(f"‚ùå Error importing TTS: {e}")
    print("Please install: pip install TTS==0.22.0")
    sys.exit(1)

# Paths
PROJECT_ROOT = Path("f:/CODE/tts-2")
MODEL_DIR = PROJECT_ROOT / "run" / "training_milliomos" / "XTTS_20251002_2323-October-02-2025_11+23PM-06571a9"
OUTPUT_DIR = PROJECT_ROOT / "test_outputs"
DATASET_PATH = PROJECT_ROOT / "dataset_milliomos"

# Reference audios for different styles
REFERENCE_AUDIOS = {
    "greeting": str(DATASET_PATH / "greeting" / "greeting_001.wav"),
    "excitement": str(DATASET_PATH / "excitement" / "excitement_001.wav"),
    "question": str(DATASET_PATH / "question" / "question_003.wav"),  # Updated after reclassification
    "tension": str(DATASET_PATH / "tension" / "tension_002.wav"),  # Updated after reclassification
}

# Test phrases from Milliomos show
TEST_PHRASES = [
    ("greeting", "Gratul√°lok! Helyes v√°lasz!"),
    ("greeting", "Szeretettel k√∂sz√∂nt√∂m n√©z≈ëinket!"),
    ("greeting", "Nagyszer≈± teljes√≠tm√©ny!"),
    
    ("excitement", "Ez m√°r m√°sf√©l milli√≥ forint!"),
    ("excitement", "Hihetetlen! Fantasztikus j√°t√©k!"),
    ("excitement", "Folytatja a gy≈ëzelmi sz√©ri√°t!"),
    
    ("question", "J√∂jj√∂n a k√∂vetkez≈ë k√©rd√©s!"),
    ("question", "Melyik √©vben volt a moh√°csi csata?"),
    ("question", "Ki festette a Mona Lis√°t?"),
    
    ("tension", "Ez egy nagyon neh√©z k√©rd√©s."),
    ("tension", "Gondolkodjon csak nyugodtan!"),
    ("tension", "Biztos benne?"),
]


def load_trained_model():
    """Load the trained model from trainer checkpoint"""
    print("="*60)
    print("LOADING TRAINED MODEL")
    print("="*60)
    
    config_path = MODEL_DIR / "config.json"
    checkpoint_path = MODEL_DIR / "best_model.pth"
    
    if not config_path.exists():
        print(f"‚ùå Config not found: {config_path}")
        return None
    
    if not checkpoint_path.exists():
        print(f"‚ùå Checkpoint not found: {checkpoint_path}")
        return None
    
    print(f"‚úì Config: {config_path.name}")
    print(f"‚úì Checkpoint: {checkpoint_path.name}")
    print(f"‚úì Size: {checkpoint_path.stat().st_size / 1024**3:.2f} GB")
    
    try:
        # Load config
        print("\nüìã Loading configuration...")
        config = XttsConfig()
        config.load_json(str(config_path))
        
        # Initialize model  
        print("ü§ñ Initializing model...")
        model = Xtts.init_from_config(config)
        
        # Load checkpoint using model's built-in method
        # This properly initializes tokenizer and other components
        print("üíæ Loading checkpoint...")
        model.load_checkpoint(
            config,
            checkpoint_dir=str(MODEL_DIR),
            checkpoint_path=str(checkpoint_path),
            eval=True,
            use_deepspeed=False
        )
        print("‚úì Checkpoint loaded with tokenizer initialized")
        
        # Move to GPU if available
        if torch.cuda.is_available():
            print("üéÆ Moving model to GPU...")
            model.cuda()
            print("‚úì Model on GPU")
        else:
            print("üíª Using CPU (will be slower)")
        
        model.eval()
        print("‚úì Model loaded successfully!")
        
        return model, config
        
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        import traceback
        traceback.print_exc()
        return None


def generate_samples(model, config):
    """Generate test samples for all categories"""
    print("\n" + "="*60)
    print("GENERATING TEST SAMPLES")
    print("="*60)
    
    OUTPUT_DIR.mkdir(exist_ok=True)
    
    total_samples = len(TEST_PHRASES)
    success_count = 0
    
    for i, (category, text) in enumerate(TEST_PHRASES, 1):
        output_file = OUTPUT_DIR / f"{i:02d}_{category}.wav"
        ref_audio = REFERENCE_AUDIOS.get(category, REFERENCE_AUDIOS["greeting"])
        
        print(f"\n[{i}/{total_samples}] {category.upper()}")
        print(f"Text: {text}")
        print(f"Ref: {Path(ref_audio).name}")
        
        try:
            # Get conditioning latents from reference audio
            gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(
                audio_path=[ref_audio]
            )
            
            # Generate speech using inference method
            out = model.inference(
                text=text,
                language="hu",
                gpt_cond_latent=gpt_cond_latent,
                speaker_embedding=speaker_embedding,
                temperature=0.75,  # Slightly creative
                top_p=0.85,
                top_k=50,
                repetition_penalty=5.0,
                length_penalty=1.0,
            )
            
            # Save audio
            torchaudio.save(
                str(output_file),
                torch.tensor(out["wav"]).unsqueeze(0),
                24000
            )
            
            print(f"‚úÖ Saved: {output_file.name}")
            success_count += 1
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*60)
    print("GENERATION COMPLETE")
    print("="*60)
    print(f"‚úÖ Generated: {success_count}/{total_samples} samples")
    print(f"üìÅ Output: {OUTPUT_DIR}")
    
    if success_count > 0:
        print("\nüéß Listen to the samples!")
        print(f"   Generated: {OUTPUT_DIR}")
        print(f"   Originals: {DATASET_PATH}")
        print("\nüìä Compare:")
        print("   - Voice similarity to Istv√°n V√°g√≥")
        print("   - Quiz show energy and enthusiasm")
        print("   - Natural Hungarian pronunciation")
        print("   - Smoothness (no choppiness)")


def main():
    print("="*60)
    print("XTTS-V2 TRAINED MODEL TESTING")
    print("Istv√°n V√°g√≥ - Milliomos Quiz Show Voice")
    print("="*60)
    
    # Load model
    result = load_trained_model()
    if result is None:
        print("\n‚ùå Failed to load model")
        sys.exit(1)
    
    model, config = result
    
    # Generate samples
    print("\n‚è≥ Starting generation (this may take a few minutes)...")
    generate_samples(model, config)
    
    print("\n‚úÖ All done!")


if __name__ == "__main__":
    main()
