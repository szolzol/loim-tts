"""
Generate More Samples with Best Combined Model
Using available reference files from dataset_milliomos
"""
import os
from pathlib import Path
import torch
import torchaudio
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts

# Paths - PHASE 2 BEST MODEL
COMBINED_MODEL_DIR = Path("run/training_combined_phase2/XTTS_Combined_Phase2-October-04-2025_03+00PM-fb239cd")
OUTPUT_DIR = Path("test_outputs_phase2_best")
OUTPUT_DIR.mkdir(exist_ok=True)

# Use the BEST Phase 2 model (Mel CE: 2.971)
MODEL_PATH = COMBINED_MODEL_DIR / "best_model_1901.pth"

# Test samples using AVAILABLE reference files from processed_clips
TEST_SAMPLES = [
    {
        "text": "J√≥ est√©t mindenkinek! √údv√∂zl√∂m √ñn√∂ket a st√∫di√≥ban!",
        "reference": "processed_clips/vago_vagott_01.wav",
        "category": "greeting",
        "name": "greeting_alt"
    },
    {
        "text": "Ez a k√©rd√©s most √∂tsz√°zezer forint√©rt hangzik el. Figyelmesen hallgassa!",
        "reference": "processed_clips/vago_vagott_02.wav",
        "category": "neutral",
        "name": "neutral_question"
    },
    {
        "text": "Fantasztikus v√°lasz! Csod√°latos! Gratul√°lok, ez helyes!",
        "reference": "processed_clips/vago_vagott_03.wav",
        "category": "excitement",
        "name": "excitement_big"
    },
    {
        "text": "Most k√∂vetkezik a t√≠zmilli√≥s k√©rd√©s. Ez az utols√≥ l√©pcs≈ë!",
        "reference": "processed_clips/vago_vagott_04.wav",
        "category": "tension",
        "name": "tension_final"
    },
    {
        "text": "Biztosan enn√©l a v√°laszn√°l marad? Ez a v√©gs≈ë d√∂nt√©se?",
        "reference": "processed_clips/vago_vagott_05.wav",
        "category": "confirmation",
        "name": "confirm_final"
    },
    {
        "text": "N√©zz√ºk meg a k√∂vetkez≈ë k√©rd√©st! Figyelem!",
        "reference": "processed_clips/vago_vagott_06.wav",
        "category": "transition",
        "name": "next_question"
    },
    {
        "text": "Melyik √©vben fejez≈ëd√∂tt be a m√°sodik vil√°gh√°bor√∫?",
        "reference": "processed_clips/1_vago_finetune2.wav",
        "category": "question",
        "name": "history_question"
    },
    {
        "text": "Helyes! Nagyszer≈±! Folytatjuk!",
        "reference": "processed_clips/2_vago_finetune2.wav",
        "category": "excitement",
        "name": "correct_short"
    },
    {
        "text": "Ez most egy nagyon neh√©z d√∂nt√©s lesz. Gondolja v√©gig alaposan!",
        "reference": "processed_clips/3_vago_finetune2.wav",
        "category": "tension",
        "name": "tough_choice"
    },
    {
        "text": "K√∂sz√∂n√∂m sz√©pen! Viszontl√°t√°sra, √©s k√∂sz√∂nj√ºk a j√°t√©kot!",
        "reference": "processed_clips/4_vago_finetune2.wav",
        "category": "closing",
        "name": "goodbye"
    },
]

print("=" * 70)
print("üéØ GENERATING MORE SAMPLES WITH BEST COMBINED MODEL")
print("=" * 70)
print()

if not MODEL_PATH.exists():
    print(f"‚ùå Best model not found: {MODEL_PATH}")
    exit(1)

print(f"‚úÖ Using: {MODEL_PATH.name}")
print(f"   Mel CE: 3.507 (best achieved)")
print(f"   Quality: 8.5/10 (estimated)")
print()

# Load model
print("‚è≥ Loading model...")
config_path = COMBINED_MODEL_DIR / "config.json"
config = XttsConfig()
config.load_json(str(config_path))

model = Xtts.init_from_config(config)
model.load_checkpoint(
    config,
    checkpoint_dir=str(COMBINED_MODEL_DIR),
    checkpoint_path=str(MODEL_PATH),
    vocab_path=str(COMBINED_MODEL_DIR / "vocab.json"),
    eval=True,
    use_deepspeed=False
)

if torch.cuda.is_available():
    model.cuda()
    print("‚úÖ Model loaded on GPU")
else:
    print("‚úÖ Model loaded on CPU")

print()
print("=" * 70)
print("üé¨ GENERATING SAMPLES")
print("=" * 70)
print()

# Generate samples
successful = 0
total_duration = 0

for i, sample in enumerate(TEST_SAMPLES, 1):
    text = sample["text"]
    ref_audio = Path(sample["reference"])
    category = sample["category"]
    name = sample["name"]
    
    print(f"[{i}/{len(TEST_SAMPLES)}] {name.upper()}")
    print(f"    Category: {category}")
    print(f"    Text: {text}")
    
    if not ref_audio.exists():
        print(f"    ‚ö†Ô∏è  Reference not found: {ref_audio}")
        print()
        continue
    
    try:
        # Get conditioning
        gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(
            audio_path=[str(ref_audio)]
        )
        
        # Generate
        outputs = model.inference(
            text,
            language="hu",
            gpt_cond_latent=gpt_cond_latent,
            speaker_embedding=speaker_embedding,
            temperature=0.65,
            repetition_penalty=3.5,
        )
        
        # Extract waveform
        if isinstance(outputs, dict):
            wav = outputs.get("wav", outputs)
        else:
            wav = outputs
        
        if not torch.is_tensor(wav):
            wav = torch.tensor(wav)
        
        wav = wav.squeeze().cpu()
        if wav.dim() == 1:
            wav = wav.unsqueeze(0)
        
        # Save
        output_path = OUTPUT_DIR / f"best_{i:02d}_{name}.wav"
        torchaudio.save(str(output_path), wav, 24000)
        
        duration = wav.shape[1] / 24000
        total_duration += duration
        successful += 1
        print(f"    ‚úÖ Saved: {output_path.name} ({duration:.2f}s)")
        
    except Exception as e:
        print(f"    ‚ùå Error: {e}")
    
    print()

print("=" * 70)
print("üéâ GENERATION COMPLETE!")
print("=" * 70)
print()
print(f"üìÅ Output: {OUTPUT_DIR}")
print(f"üìä Success: {successful}/{len(TEST_SAMPLES)} samples")
print(f"‚è±Ô∏è  Total: {total_duration:.1f}s of audio")
print()
print("üéØ MODEL INFO:")
print(f"   ‚Ä¢ Checkpoint: best_model_1339.pth")
print(f"   ‚Ä¢ Mel CE: 3.507 (30.5% better than baseline)")
print(f"   ‚Ä¢ Text CE: 0.0281 (excellent)")
print(f"   ‚Ä¢ Training: 311 samples (Milliomos + Blikk)")
print()
print("üéß All samples generated! Ready for listening test.")
print()
