"""
Deep Semantic Reclassification of Audio Dataset
Analyzes speech content and emotional context to properly categorize audio samples
"""

import os
import shutil
import csv
from pathlib import Path
import re

PROJECT_ROOT = Path("f:/CODE/tts-2")
DATASET_PATH = PROJECT_ROOT / "dataset_milliomos"
METADATA_FILE = DATASET_PATH / "metadata.csv"
BACKUP_FILE = DATASET_PATH / "metadata_backup.csv"

# Comprehensive semantic classification rules
CLASSIFICATION_RULES = {
    'greeting': {
        'keywords': [
            'gratul√°lok', 'gratul√°l', 'k√∂sz√∂nt', 'szeretettel', '√ºdv√∂z√∂l',
            'kedves', 'j√≥ est√©t', 'hello', 'szia', '√ºdv', 'v√°runk',
            'tess√©k', 'foglaljon helyet', 'j√∂v√∂k', '√©rkezik', '√©rkezett',
            'sok szeretet', 'legyen', 'v√°rjon', 'kivel √©rkezett'
        ],
        'patterns': [
            r'gratul√°l\w*',
            r'k√∂sz√∂n\w*',
            r'szeretettel\s+\w+',
            r'kedves\s+\w+',
            r'v√°runk',
            r'√©rkezett',
            r'foglaljon\s+helyet',
            r'tess√©k\s+\w+'
        ],
        'sentiment': 'positive_welcoming',
        'description': 'Welcoming phrases, congratulations, greetings, introductions'
    },
    
    'excitement': {
        'keywords': [
            'helyes', '√≠gy van', '√≠gy is van', 'fantasztikus', 'nagyszer≈±',
            'sz√©p', 'igen', 'j√≥kor', 'garant√°lt', 'nyerem√©ny', 'milli√≥',
            'forint', 'sikeres', 'pomp√°s', 'remek', 'el√©g j√≥l',
            'konstat√°lhat', '√©rdekes', 'vil√°gh√≠r≈±', 'bizony', 'igaza van',
            'egyet', 't√∂k√©letes', 'helyes v√°lasz', 'br√°v√≥', 'kiv√°l√≥'
        ],
        'patterns': [
            r'helyes\s*[!,.]',
            r'√≠gy\s+van',
            r'√≠gy\s+is\s+van',
            r'\d+\s*(milli√≥|ezer)\s*forint',
            r'garant√°lt\s+\w+',
            r'nagyszer≈±\w*',
            r'fantasztikus',
            r'igaza\s+van',
            r'bizony\s+bizony'
        ],
        'sentiment': 'positive_excited',
        'description': 'Positive feedback, excitement about money, affirmation of correct answers'
    },
    
    'question': {
        'keywords': [
            'melyik', 'milyen', 'ki nem', 'mi volt', 'hogyan', 'hol',
            'mikor', 'mi√©rt', 'mi a neve', 'tegy√©k', 'n√©zz√ºk', 'k√©rd√©s',
            'v√°lasz', 'mondja', 'mit jelent', 'eml√≠tse meg', 'sorolja fel',
            'nevez', 'h√≠v', 'sz√°rmaz', 'magyar√°z'
        ],
        'patterns': [
            r'^melyik\s+\w+',
            r'^milyen\s+\w+',
            r'^ki\s+(nem\s+)?volt',
            r'^mi\s+(volt|a\s+neve|jelent)',
            r'^hogyan\s+\w+',
            r'^hol\s+\w+',
            r'^mikor\s+\w+',
            r'^mi√©rt\s+\w+',
            r'tegy√©k\s+\w+\s+sorrendbe',
            r'k√©rd√©s.*\?$',
            r'\?\s*$'  # Ends with question mark
        ],
        'anti_patterns': [
            r'ez\s+a\s+k√©rd√©s',  # Talking about question, not asking
            r'sz√©p\s+k√©rd√©s',
            r'neh√©z\s+k√©rd√©s'
        ],
        'sentiment': 'neutral_inquiring',
        'description': 'Direct questions, quiz questions, asking for information'
    },
    
    'tension': {
        'keywords': [
            'biztos', 'meggy≈ëz≈ëd√©s', 'retteg', 'biztos benne', 'elk√©pzelhet≈ë',
            'vagy', 'esetleg', 'neh√©z', 'rem√©lem', 'gondol', '√∫gy √©rzi',
            'meg√©rz√©s', 'vacakol', 'csal√≥dott', 'rossz h√≠r', 'tudja',
            'nem tudom', 'seg√≠t', 'kicsit seg√≠t', 'v√°laszt', 'kiz√°r',
            'zaklat', 'elveszt', 'elpukkan', '√©rz√©kel'
        ],
        'patterns': [
            r'biztos\s+(benne|vagy)',
            r'elk√©pzelhet≈ë',
            r'vagy\s+\w+\s+vagy',  # "vagy X vagy Y"
            r'esetleg',
            r'ne\s+\w+',
            r'nem\s+tudom',
            r'retteg\w*',
            r'rem√©lem',
            r'meg√©rz√©s',
            r'seg√≠t\w*',
            r'kiz√°r\w*',
            r'elveszt\w*'
        ],
        'sentiment': 'uncertain_tense',
        'description': 'Uncertainty, doubt, tension, deliberation, choices between options'
    },
    
    'neutral': {
        'keywords': [
            'tulajdonk√©ppen', 'teh√°t', '√∫gyhogy', 'ugyanis', 'mert',
            'az√©rt', 'viszont', 'azonban', 'mivel', '√≠gy', 'akkor',
            'most', 'ebben', 'ott', 'itt', 'amikor', 'amely'
        ],
        'patterns': [
            r'^teh√°t\s+\w+',
            r'tulajdonk√©ppen',
            r'√∫gyhogy',
            r'viszont',
            r'azonban'
        ],
        'sentiment': 'neutral_explanatory',
        'description': 'Explanatory statements, neutral commentary, factual information'
    },
    
    'transition': {
        'keywords': [
            'akkor', 'most', 'na', 'j√≥', 'rendben', 'tess√©k', 'n√©zz√ºk',
            'l√°ssuk', 'folytat√≥d', 'k√∂vetkez≈ë', 'tov√°bb', 'itt van',
            'na j√≥', 'h√°t akkor', 'na most', '√©s akkor', 'ezek szerint'
        ],
        'patterns': [
            r'^na\s+(j√≥|most|akkor)',
            r'^h√°t\s+akkor',
            r'^√©s\s+akkor',
            r'^akkor\s+\w+',
            r'^most\s+\w+',
            r'^tess√©k',
            r'^n√©zz√ºk',
            r'^l√°ssuk',
            r'k√∂vetkez≈ë\s+\w+',
            r'folytat√≥d\w*',
            r'itt\s+van',
            r'rendben\s+van'
        ],
        'sentiment': 'neutral_transitional',
        'description': 'Transitional phrases, moving between topics, procedural statements'
    },
    
    'confirmation': {
        'keywords': [
            'igen', 'j√≥', 'ok√©', 'rendben', 'megvan', '√©rtem',
            'persze', 'term√©szetesen', '√∫gy van', 'pontosan',
            'meg√©rtettem', 'vil√°gos', 'k√©sz'
        ],
        'patterns': [
            r'^igen[,.]',
            r'^j√≥[,.]',
            r'^rendben',
            r'^megvan',
            r'pontosan',
            r'term√©szetesen'
        ],
        'sentiment': 'neutral_confirming',
        'description': 'Simple confirmations, acknowledgments, short agreements'
    }
}


def analyze_semantic_category(text):
    """
    Deep semantic analysis to determine the true category
    Returns: (category, confidence_score, reasoning)
    """
    text_lower = text.lower()
    
    # Clean text
    text_lower = re.sub(r'\[.*?\]', '', text_lower)  # Remove [√°thall√°s] etc.
    text_lower = text_lower.strip()
    
    scores = {category: 0 for category in CLASSIFICATION_RULES.keys()}
    reasons = {category: [] for category in CLASSIFICATION_RULES.keys()}
    
    # Score each category
    for category, rules in CLASSIFICATION_RULES.items():
        # Check keywords
        for keyword in rules['keywords']:
            if keyword in text_lower:
                scores[category] += 2
                reasons[category].append(f"keyword: '{keyword}'")
        
        # Check patterns
        for pattern in rules.get('patterns', []):
            if re.search(pattern, text_lower):
                scores[category] += 3
                reasons[category].append(f"pattern: {pattern}")
        
        # Check anti-patterns (reduce score)
        for anti_pattern in rules.get('anti_patterns', []):
            if re.search(anti_pattern, text_lower):
                scores[category] -= 5
                reasons[category].append(f"ANTI-pattern: {anti_pattern}")
    
    # Additional contextual rules
    
    # Questions should end with ? or have question words at start
    if text_lower.endswith('?'):
        scores['question'] += 5
        reasons['question'].append("ends with ?")
    
    # Questions shouldn't be about the question itself
    if 'ez a k√©rd√©s' in text_lower or 'neh√©z k√©rd√©s' in text_lower:
        scores['question'] -= 3
        scores['tension'] += 2
        reasons['tension'].append("meta-discussion about question")
    
    # Short affirmations are confirmations
    if len(text_lower.split()) <= 5 and any(word in text_lower for word in ['igen', 'j√≥', 'rendben', 'ok√©']):
        scores['confirmation'] += 3
        reasons['confirmation'].append("short affirmation")
    
    # Money amounts = excitement
    if re.search(r'\d+\s*(milli√≥|ezer)', text_lower):
        scores['excitement'] += 4
        reasons['excitement'].append("mentions money amount")
    
    # "√≠gy van", "helyes" = excitement (positive feedback)
    if re.search(r'(√≠gy\s+(is\s+)?van|helyes)', text_lower):
        scores['excitement'] += 3
        reasons['excitement'].append("positive affirmation")
    
    # Long explanatory text = neutral or transition
    if len(text_lower.split()) > 30:
        scores['neutral'] += 2
        scores['transition'] += 1
        reasons['neutral'].append("long explanatory text")
    
    # Multiple "vagy" = tension (offering choices)
    vagy_count = text_lower.count(' vagy ')
    if vagy_count >= 2:
        scores['tension'] += vagy_count * 2
        reasons['tension'].append(f"multiple choices ({vagy_count}x 'vagy')")
    
    # "na" at start = transition
    if text_lower.startswith('na '):
        scores['transition'] += 3
        reasons['transition'].append("starts with 'na'")
    
    # Find best category
    best_category = max(scores, key=scores.get)
    best_score = scores[best_category]
    
    # Calculate confidence (0-100)
    total_score = sum(scores.values())
    confidence = (best_score / total_score * 100) if total_score > 0 else 0
    
    # If score is too low or confidence is too low, mark as neutral
    if best_score < 2 or confidence < 30:
        best_category = 'neutral'
        confidence = 50
    
    reasoning = "; ".join(reasons[best_category][:3])  # Top 3 reasons
    
    return best_category, confidence, reasoning


def reclassify_dataset():
    """Reclassify all audio samples based on semantic analysis"""
    
    print("="*70)
    print("DEEP SEMANTIC RECLASSIFICATION")
    print("Istv√°n V√°g√≥ Milliomos Dataset")
    print("="*70)
    
    # Backup original metadata
    print(f"\nüìã Backing up metadata...")
    shutil.copy(METADATA_FILE, BACKUP_FILE)
    print(f"‚úì Backup created: {BACKUP_FILE.name}")
    
    # Read metadata
    print(f"\nüìñ Reading metadata...")
    with open(METADATA_FILE, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f, delimiter='|')
        rows = list(reader)
    
    print(f"‚úì Found {len(rows)} samples")
    
    # Analyze and reclassify
    print(f"\nüîç Analyzing semantic content...\n")
    
    reclassifications = []
    stats = {
        'unchanged': 0,
        'changed': 0,
        'by_category': {}
    }
    
    for i, row in enumerate(rows, 1):
        audio_file = row['audio_file']
        text = row['text']
        speaker = row['speaker_name']
        
        # Get current category
        current_category = audio_file.split('/')[0]
        
        # Analyze
        new_category, confidence, reasoning = analyze_semantic_category(text)
        
        # Track stats
        if new_category not in stats['by_category']:
            stats['by_category'][new_category] = 0
        stats['by_category'][new_category] += 1
        
        if new_category != current_category:
            stats['changed'] += 1
            status = "üîÑ CHANGE"
            
            reclassifications.append({
                'old_path': audio_file,
                'new_category': new_category,
                'text': text,
                'confidence': confidence,
                'reasoning': reasoning
            })
            
            print(f"[{i:2d}] {status}")
            print(f"     Old: {current_category}")
            print(f"     New: {new_category} ({confidence:.0f}% confidence)")
            print(f"     Text: {text[:70]}...")
            print(f"     Why: {reasoning}")
            print()
        else:
            stats['unchanged'] += 1
    
    # Show summary
    print("\n" + "="*70)
    print("RECLASSIFICATION SUMMARY")
    print("="*70)
    print(f"‚úì Total samples analyzed: {len(rows)}")
    print(f"‚úì Unchanged: {stats['unchanged']}")
    print(f"üîÑ Changed: {stats['changed']}")
    print(f"\nüìä Category distribution:")
    for category, count in sorted(stats['by_category'].items()):
        print(f"   {category:15s}: {count:2d} samples")
    
    if stats['changed'] == 0:
        print("\n‚úÖ No changes needed - all samples correctly classified!")
        return
    
    # Ask for confirmation
    print(f"\n{'='*70}")
    print(f"Found {stats['changed']} samples to reclassify.")
    print(f"This will:")
    print(f"  1. Move audio files to new category folders")
    print(f"  2. Update metadata.csv with new paths")
    print(f"  3. Keep backup at: {BACKUP_FILE.name}")
    
    response = input(f"\nProceed with reclassification? (yes/no): ").strip().lower()
    
    if response != 'yes':
        print("\n‚ùå Reclassification cancelled.")
        return
    
    # Perform reclassification
    print(f"\nüîß Reclassifying files...")
    
    for reclass in reclassifications:
        old_path = DATASET_PATH / reclass['old_path']
        old_filename = old_path.name
        
        # Generate new path
        new_category_dir = DATASET_PATH / reclass['new_category']
        new_category_dir.mkdir(exist_ok=True)
        
        # Find next available number in new category
        existing_files = list(new_category_dir.glob(f"{reclass['new_category']}_*.wav"))
        if existing_files:
            numbers = [int(f.stem.split('_')[-1]) for f in existing_files]
            next_num = max(numbers) + 1
        else:
            next_num = 1
        
        new_filename = f"{reclass['new_category']}_{next_num:03d}.wav"
        new_path = new_category_dir / new_filename
        
        # Move file
        if old_path.exists():
            shutil.move(str(old_path), str(new_path))
            print(f"   Moved: {reclass['old_path']} -> {reclass['new_category']}/{new_filename}")
            
            # Update reclass dict with actual new path
            reclass['new_path'] = f"{reclass['new_category']}/{new_filename}"
        else:
            print(f"   ‚ö†Ô∏è  File not found: {old_path}")
            reclass['new_path'] = reclass['old_path']  # Keep old path
    
    # Update metadata.csv
    print(f"\nüìù Updating metadata.csv...")
    
    # Create lookup of old paths to new paths
    path_mapping = {r['old_path']: r['new_path'] for r in reclassifications}
    
    # Update rows
    for row in rows:
        if row['audio_file'] in path_mapping:
            row['audio_file'] = path_mapping[row['audio_file']]
    
    # Write updated metadata
    with open(METADATA_FILE, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=['audio_file', 'text', 'speaker_name'], delimiter='|')
        writer.writeheader()
        writer.writerows(rows)
    
    print(f"‚úì Metadata updated")
    
    # Save reclassification report
    report_file = DATASET_PATH / "reclassification_report.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("RECLASSIFICATION REPORT\n")
        f.write("="*70 + "\n\n")
        f.write(f"Total changes: {len(reclassifications)}\n\n")
        
        for i, reclass in enumerate(reclassifications, 1):
            f.write(f"[{i}]\n")
            f.write(f"Old: {reclass['old_path']}\n")
            f.write(f"New: {reclass['new_path']}\n")
            f.write(f"Confidence: {reclass['confidence']:.0f}%\n")
            f.write(f"Reasoning: {reclass['reasoning']}\n")
            f.write(f"Text: {reclass['text']}\n")
            f.write("\n")
    
    print(f"‚úì Report saved: {report_file.name}")
    
    print("\n" + "="*70)
    print("‚úÖ RECLASSIFICATION COMPLETE!")
    print("="*70)
    print(f"üìÅ Files moved and organized by semantic category")
    print(f"üìã Metadata updated: {METADATA_FILE.name}")
    print(f"üíæ Backup available: {BACKUP_FILE.name}")
    print(f"üìÑ Detailed report: {report_file.name}")


if __name__ == "__main__":
    reclassify_dataset()
