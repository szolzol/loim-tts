#!/usr/bin/env python3
"""
Intelligens V√°g√≥ Istv√°n klip kiv√°g√≥
ElevenLabs min≈ës√©g el√©r√©se √©rdek√©ben
"""

import os
import sys
import librosa
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import torchaudio
import torch
from scipy import signal
from typing import List, Tuple, Dict
import json

class VagoClipExtractor:
    def __init__(self, source_file: str = "vago_vagott.mp3"):
        """V√°g√≥ Istv√°n klip kiv√°g√≥ inicializ√°l√°sa"""
        self.source_file = source_file
        self.output_dir = Path("processed_audio")
        self.output_dir.mkdir(exist_ok=True)
        
        # Audio anal√≠zis param√©terei
        self.min_clip_duration = 3.0  # Minimum klip hossz (m√°sodperc)
        self.max_clip_duration = 15.0  # Maximum klip hossz
        self.target_duration = 8.0     # Ide√°lis klip hossz
        self.min_snr = 15.0           # Minimum jel-zaj ar√°ny (dB)
        self.min_rms_energy = 0.02    # Minimum energia szint
        
    def analyze_audio_quality(self, audio: np.ndarray, sr: int) -> Dict:
        """R√©szletes audio min≈ës√©g anal√≠zis"""
        
        # Alapvet≈ë metrik√°k
        duration = len(audio) / sr
        rms_energy = np.sqrt(np.mean(audio**2))
        peak_amplitude = np.max(np.abs(audio))
        dynamic_range = peak_amplitude - np.min(np.abs(audio[audio != 0]))
        
        # SNR sz√°m√≠t√°s spektr√°lis m√≥dszerrel
        snr_db = self._calculate_snr(audio, sr)
        
        # Pitch stabilit√°s
        pitch_stability = self._calculate_pitch_stability(audio, sr)
        
        # Spektr√°lis tisztas√°g
        spectral_clarity = self._calculate_spectral_clarity(audio, sr)
        
        # H√°tt√©rzaj szint
        noise_level = self._estimate_noise_level(audio, sr)
        
        # √ñsszes√≠tett min≈ës√©gi pontsz√°m (0-100)
        quality_score = self._calculate_quality_score(
            snr_db, rms_energy, pitch_stability, spectral_clarity, noise_level
        )
        
        return {
            'duration': duration,
            'rms_energy': rms_energy,
            'peak_amplitude': peak_amplitude,
            'dynamic_range': dynamic_range,
            'snr_db': snr_db,
            'pitch_stability': pitch_stability,
            'spectral_clarity': spectral_clarity,
            'noise_level': noise_level,
            'quality_score': quality_score
        }
    
    def _calculate_snr(self, audio: np.ndarray, sr: int) -> float:
        """Jel-zaj ar√°ny sz√°m√≠t√°sa fejlett spektr√°lis m√≥dszerrel"""
        
        # Spektrogramm sz√°m√≠t√°s
        f, t, Sxx = signal.spectrogram(audio, sr, nperseg=2048)
        
        # Besz√©d frekvencia tartom√°ny: 85Hz - 8000Hz
        speech_mask = (f >= 85) & (f <= 8000)
        noise_mask = f > 8000  # Magasabb frekvenci√°k zajnak
        
        # √Åtlagos teljes√≠tm√©ny
        speech_power = np.mean(Sxx[speech_mask, :])
        noise_power = np.mean(Sxx[noise_mask, :]) if np.any(noise_mask) else np.percentile(Sxx[speech_mask, :], 5)
        
        # SNR dB-ben
        snr_ratio = speech_power / (noise_power + 1e-10)
        return 10 * np.log10(snr_ratio)
    
    def _calculate_pitch_stability(self, audio: np.ndarray, sr: int) -> float:
        """Pitch stabilit√°s sz√°m√≠t√°sa"""
        try:
            # F0 extrakci√≥
            f0, voiced_flag, voiced_probs = librosa.pyin(
                audio, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')
            )
            
            # Csak a hangz√≥ r√©szek
            voiced_f0 = f0[voiced_flag]
            
            if len(voiced_f0) < 10:
                return 0.0
            
            # Stabilit√°s = 1 - (std / mean)
            f0_mean = np.mean(voiced_f0)
            f0_std = np.std(voiced_f0)
            stability = max(0.0, 1.0 - (f0_std / f0_mean))
            
            return stability
            
        except Exception:
            return 0.5  # Default √©rt√©k hiba eset√©n
    
    def _calculate_spectral_clarity(self, audio: np.ndarray, sr: int) -> float:
        """Spektr√°lis tisztas√°g sz√°m√≠t√°sa"""
        
        # Spektr√°lis centroid
        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
        
        # Spektr√°lis rolloff
        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, roll_percent=0.85)[0]
        
        # Spektr√°lis kontrast
        spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)
        contrast_mean = np.mean(spectral_contrast)
        
        # Harmonicit√°s (MFCC alap√∫ k√∂zel√≠t√©s)
        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        harmonic_clarity = 1.0 / (1.0 + np.std(mfccs[1:4]))  # Els≈ë n√©h√°ny MFCC
        
        # Kombin√°lt tisztas√°g (0-1)
        clarity = (
            0.3 * min(contrast_mean / 10.0, 1.0) +
            0.3 * harmonic_clarity +
            0.4 * min(np.mean(spectral_centroids) / 3000.0, 1.0)
        )
        
        return clarity
    
    def _estimate_noise_level(self, audio: np.ndarray, sr: int) -> float:
        """H√°tt√©rzaj szint becsl√©se"""
        
        # Csend r√©szek detekt√°l√°sa (alacsony energia)
        frame_length = int(0.025 * sr)  # 25ms frames
        hop_length = int(0.010 * sr)    # 10ms hop
        
        # Frame-enk√©nti energia
        frames = librosa.util.frame(audio, frame_length=frame_length, hop_length=hop_length)
        frame_energies = np.mean(frames**2, axis=0)
        
        # Legalacsonyabb 10% energia = zaj szint
        noise_level = np.percentile(frame_energies, 10)
        
        return float(np.sqrt(noise_level))
    
    def _calculate_quality_score(self, snr_db: float, rms_energy: float, 
                                pitch_stability: float, spectral_clarity: float, 
                                noise_level: float) -> float:
        """√ñsszes√≠tett min≈ës√©gi pontsz√°m (0-100)"""
        
        # SNR pontsz√°m (0-30)
        snr_score = min(snr_db, 30.0)
        
        # Energia pontsz√°m (0-20)
        energy_score = min(rms_energy * 500, 20.0)  # 0.04 RMS = 20 pont
        
        # Pitch stabilit√°s pontsz√°m (0-25)
        pitch_score = pitch_stability * 25.0
        
        # Spektr√°lis tisztas√°g pontsz√°m (0-20)
        clarity_score = spectral_clarity * 20.0
        
        # Zaj b√ºntet√©s (0-5)
        noise_penalty = min(noise_level * 100, 5.0)
        
        # √ñsszes pontsz√°m
        total_score = snr_score + energy_score + pitch_score + clarity_score - noise_penalty
        
        return max(0.0, min(100.0, total_score))
    
    def find_best_segments(self, target_count: int = 8) -> List[Tuple[float, float, float]]:
        """Legjobb audio szegmensek megkeres√©se"""
        
        print(f"üîç Audio anal√≠zis: {self.source_file}")
        
        # Audio bet√∂lt√©s
        audio, sr = librosa.load(self.source_file, sr=None)
        total_duration = len(audio) / sr
        
        print(f"üìä Teljes hossz: {total_duration:.1f} m√°sodperc")
        print(f"üì° Sample rate: {sr} Hz")
        
        # Ablak param√©terek
        window_duration = self.target_duration
        step_duration = 2.0  # 2 m√°sodpercenk√©nt pr√≥b√°lunk
        
        segments = []
        
        # V√©gigszkennelj√ºk az eg√©sz f√°jlt
        current_time = 0.0
        while current_time + window_duration <= total_duration:
            
            # Aktu√°lis szegmens kiv√°g√°sa
            start_sample = int(current_time * sr)
            end_sample = int((current_time + window_duration) * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # Min≈ës√©g anal√≠zis
            quality_metrics = self.analyze_audio_quality(segment_audio, sr)
            
            # Szegmens hozz√°ad√°sa ha megfelel a krit√©riumoknak
            if (quality_metrics['snr_db'] >= self.min_snr and 
                quality_metrics['rms_energy'] >= self.min_rms_energy):
                
                segments.append((
                    current_time, 
                    current_time + window_duration,
                    quality_metrics['quality_score']
                ))
                
                print(f"   ‚úÖ {current_time:.1f}s-{current_time + window_duration:.1f}s: "
                      f"Q={quality_metrics['quality_score']:.1f}, "
                      f"SNR={quality_metrics['snr_db']:.1f}dB, "
                      f"RMS={quality_metrics['rms_energy']:.3f}")
            else:
                print(f"   ‚ùå {current_time:.1f}s-{current_time + window_duration:.1f}s: "
                      f"SNR={quality_metrics['snr_db']:.1f}dB, "
                      f"RMS={quality_metrics['rms_energy']:.3f}")
            
            current_time += step_duration
        
        # Legjobb szegmensek kiv√°laszt√°sa
        segments.sort(key=lambda x: x[2], reverse=True)  # Min≈ës√©g szerint rendez√©s
        best_segments = segments[:target_count]
        
        print(f"\nüéØ {len(best_segments)} legjobb szegmens kiv√°lasztva!")
        
        return best_segments
    
    def extract_clips(self, target_count: int = 8):
        """Klipek kiv√°g√°sa √©s ment√©se"""
        
        # Legjobb szegmensek megkeres√©se
        segments = self.find_best_segments(target_count)
        
        if not segments:
            print("‚ùå Nem tal√°lhat√≥k megfelel≈ë min≈ës√©g≈± szegmensek!")
            return
        
        # Audio bet√∂lt√©s
        audio, sr = librosa.load(self.source_file, sr=None)
        
        print(f"\nüé¨ Klipek kiv√°g√°sa...")
        
        extracted_clips = []
        
        for i, (start_time, end_time, quality_score) in enumerate(segments, 1):
            
            # Szegmens kiv√°g√°sa
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # F√°jln√©v gener√°l√°s
            output_filename = f"vago_premium_clip_{i:02d}_q{quality_score:.0f}.wav"
            output_path = self.output_dir / output_filename
            
            # Ment√©s
            segment_tensor = torch.from_numpy(segment_audio).unsqueeze(0)
            torchaudio.save(str(output_path), segment_tensor, sr)
            
            extracted_clips.append(str(output_path))
            
            print(f"   üíæ {output_filename}: {start_time:.1f}s-{end_time:.1f}s "
                  f"(Q={quality_score:.1f})")
        
        print(f"\n‚úÖ {len(extracted_clips)} pr√©mium klip elk√©sz√ºlt!")
        print(f"üìÅ Ment√©si hely: {self.output_dir}")
        
        # Klipek √∂sszes√≠t≈ë jelent√©se
        self._generate_clip_report(extracted_clips)
        
        return extracted_clips
    
    def _generate_clip_report(self, clips: List[str]):
        """Klipek min≈ës√©gi jelent√©s√©nek gener√°l√°sa"""
        
        report = {
            'timestamp': str(np.datetime64('now')),
            'source_file': self.source_file,
            'clips': []
        }
        
        print(f"\nüìä MIN≈êS√âGI JELENT√âS")
        print("=" * 50)
        
        for clip_path in clips:
            # Audio bet√∂lt√©s √©s anal√≠zis
            audio, sr = torchaudio.load(clip_path)
            audio_np = audio.squeeze().numpy()
            
            metrics = self.analyze_audio_quality(audio_np, sr)
            
            clip_info = {
                'filename': Path(clip_path).name,
                'path': clip_path,
                'metrics': metrics
            }
            
            report['clips'].append(clip_info)
            
            print(f"üéµ {Path(clip_path).name}")
            print(f"   ‚è±Ô∏è Id≈ëtartam: {metrics['duration']:.1f}s")
            print(f"   üì° SNR: {metrics['snr_db']:.1f}dB")
            print(f"   ‚ö° RMS energia: {metrics['rms_energy']:.3f}")
            print(f"   üéØ Pitch stabilit√°s: {metrics['pitch_stability']:.2f}")
            print(f"   üåä Spektr√°lis tisztas√°g: {metrics['spectral_clarity']:.2f}")
            print(f"   üèÜ Min≈ës√©gi pontsz√°m: {metrics['quality_score']:.1f}/100")
            print()
        
        # Jelent√©s ment√©se
        report_path = self.output_dir / "vago_clips_quality_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"üìã R√©szletes jelent√©s mentve: {report_path}")

def main():
    """F≈ëprogram"""
    
    print("üéôÔ∏è V√°g√≥ Istv√°n Pr√©mium Klip Kiv√°g√≥")
    print("=" * 40)
    
    # Ellen≈ërz√©s: l√©tezik-e a forr√°sf√°jl
    source_file = "vago_vagott.mp3"
    if not os.path.exists(source_file):
        print(f"‚ùå Forr√°sf√°jl nem tal√°lhat√≥: {source_file}")
        return
    
    # Kiv√°g√≥ p√©ld√°ny
    extractor = VagoClipExtractor(source_file)
    
    # Klipek kiv√°g√°sa
    clips = extractor.extract_clips(target_count=8)
    
    if clips:
        print(f"\nüéâ SIKER! {len(clips)} pr√©mium klip elk√©sz√ºlt!")
        print("üöÄ Ezek haszn√°lhat√≥k ElevenLabs min≈ës√©g≈± TTS-hez!")
    else:
        print("‚ùå Nem siker√ºlt megfelel≈ë klipeket kiv√°gni.")

if __name__ == "__main__":
    main()