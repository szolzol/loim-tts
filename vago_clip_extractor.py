#!/usr/bin/env python3
"""
Intelligens VÃ¡gÃ³ IstvÃ¡n klip kivÃ¡gÃ³
ElevenLabs minÅ‘sÃ©g elÃ©rÃ©se Ã©rdekÃ©ben
"""

import os
import sys
import librosa
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import torchaudio
import torch
from scipy import signal
from typing import List, Tuple, Dict
import json

class VagoClipExtractor:
    def __init__(self, source_file: str = "vago_vagott.mp3"):
        """VÃ¡gÃ³ IstvÃ¡n klip kivÃ¡gÃ³ inicializÃ¡lÃ¡sa"""
        self.source_file = source_file
        self.output_dir = Path("processed_audio")
        self.output_dir.mkdir(exist_ok=True)
        
        # Audio analÃ­zis paramÃ©terei
        self.min_clip_duration = 3.0  # Minimum klip hossz (mÃ¡sodperc)
        self.max_clip_duration = 15.0  # Maximum klip hossz
        self.target_duration = 8.0     # IdeÃ¡lis klip hossz
        self.min_snr = 15.0           # Minimum jel-zaj arÃ¡ny (dB)
        self.min_rms_energy = 0.02    # Minimum energia szint
        
    def analyze_audio_quality(self, audio: np.ndarray, sr: int) -> Dict:
        """RÃ©szletes audio minÅ‘sÃ©g analÃ­zis"""
        
        # AlapvetÅ‘ metrikÃ¡k
        duration = len(audio) / sr
        rms_energy = np.sqrt(np.mean(audio**2))
        peak_amplitude = np.max(np.abs(audio))
        dynamic_range = peak_amplitude - np.min(np.abs(audio[audio != 0]))
        
        # SNR szÃ¡mÃ­tÃ¡s spektrÃ¡lis mÃ³dszerrel
        snr_db = self._calculate_snr(audio, sr)
        
        # Pitch stabilitÃ¡s
        pitch_stability = self._calculate_pitch_stability(audio, sr)
        
        # SpektrÃ¡lis tisztasÃ¡g
        spectral_clarity = self._calculate_spectral_clarity(audio, sr)
        
        # HÃ¡ttÃ©rzaj szint
        noise_level = self._estimate_noise_level(audio, sr)
        
        # Ã–sszesÃ­tett minÅ‘sÃ©gi pontszÃ¡m (0-100)
        quality_score = self._calculate_quality_score(
            snr_db, rms_energy, pitch_stability, spectral_clarity, noise_level
        )
        
        return {
            'duration': duration,
            'rms_energy': rms_energy,
            'peak_amplitude': peak_amplitude,
            'dynamic_range': dynamic_range,
            'snr_db': snr_db,
            'pitch_stability': pitch_stability,
            'spectral_clarity': spectral_clarity,
            'noise_level': noise_level,
            'quality_score': quality_score
        }
    
    def _calculate_snr(self, audio: np.ndarray, sr: int) -> float:
        """Jel-zaj arÃ¡ny szÃ¡mÃ­tÃ¡sa fejlett spektrÃ¡lis mÃ³dszerrel"""
        
        # Spektrogramm szÃ¡mÃ­tÃ¡s
        f, t, Sxx = signal.spectrogram(audio, sr, nperseg=2048)
        
        # BeszÃ©d frekvencia tartomÃ¡ny: 85Hz - 8000Hz
        speech_mask = (f >= 85) & (f <= 8000)
        noise_mask = f > 8000  # Magasabb frekvenciÃ¡k zajnak
        
        # Ãtlagos teljesÃ­tmÃ©ny
        speech_power = np.mean(Sxx[speech_mask, :])
        noise_power = np.mean(Sxx[noise_mask, :]) if np.any(noise_mask) else np.percentile(Sxx[speech_mask, :], 5)
        
        # SNR dB-ben
        snr_ratio = speech_power / (noise_power + 1e-10)
        return 10 * np.log10(snr_ratio)
    
    def _calculate_pitch_stability(self, audio: np.ndarray, sr: int) -> float:
        """Pitch stabilitÃ¡s szÃ¡mÃ­tÃ¡sa"""
        try:
            # F0 extrakciÃ³
            f0, voiced_flag, voiced_probs = librosa.pyin(
                audio, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')
            )
            
            # Csak a hangzÃ³ rÃ©szek
            voiced_f0 = f0[voiced_flag]
            
            if len(voiced_f0) < 10:
                return 0.0
            
            # StabilitÃ¡s = 1 - (std / mean)
            f0_mean = np.mean(voiced_f0)
            f0_std = np.std(voiced_f0)
            stability = max(0.0, 1.0 - (f0_std / f0_mean))
            
            return stability
            
        except Exception:
            return 0.5  # Default Ã©rtÃ©k hiba esetÃ©n
    
    def _calculate_spectral_clarity(self, audio: np.ndarray, sr: int) -> float:
        """SpektrÃ¡lis tisztasÃ¡g szÃ¡mÃ­tÃ¡sa"""
        
        # SpektrÃ¡lis centroid
        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
        
        # SpektrÃ¡lis rolloff
        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, roll_percent=0.85)[0]
        
        # SpektrÃ¡lis kontrast
        spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)
        contrast_mean = np.mean(spectral_contrast)
        
        # HarmonicitÃ¡s (MFCC alapÃº kÃ¶zelÃ­tÃ©s)
        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        harmonic_clarity = 1.0 / (1.0 + np.std(mfccs[1:4]))  # ElsÅ‘ nÃ©hÃ¡ny MFCC
        
        # KombinÃ¡lt tisztasÃ¡g (0-1)
        clarity = (
            0.3 * min(contrast_mean / 10.0, 1.0) +
            0.3 * harmonic_clarity +
            0.4 * min(np.mean(spectral_centroids) / 3000.0, 1.0)
        )
        
        return clarity
    
    def _estimate_noise_level(self, audio: np.ndarray, sr: int) -> float:
        """HÃ¡ttÃ©rzaj szint becslÃ©se"""
        
        # Csend rÃ©szek detektÃ¡lÃ¡sa (alacsony energia)
        frame_length = int(0.025 * sr)  # 25ms frames
        hop_length = int(0.010 * sr)    # 10ms hop
        
        # Frame-enkÃ©nti energia
        frames = librosa.util.frame(audio, frame_length=frame_length, hop_length=hop_length)
        frame_energies = np.mean(frames**2, axis=0)
        
        # Legalacsonyabb 10% energia = zaj szint
        noise_level = np.percentile(frame_energies, 10)
        
        return float(np.sqrt(noise_level))
    
    def _calculate_quality_score(self, snr_db: float, rms_energy: float, 
                                pitch_stability: float, spectral_clarity: float, 
                                noise_level: float) -> float:
        """Ã–sszesÃ­tett minÅ‘sÃ©gi pontszÃ¡m (0-100)"""
        
        # SNR pontszÃ¡m (0-30)
        snr_score = min(snr_db, 30.0)
        
        # Energia pontszÃ¡m (0-20)
        energy_score = min(rms_energy * 500, 20.0)  # 0.04 RMS = 20 pont
        
        # Pitch stabilitÃ¡s pontszÃ¡m (0-25)
        pitch_score = pitch_stability * 25.0
        
        # SpektrÃ¡lis tisztasÃ¡g pontszÃ¡m (0-20)
        clarity_score = spectral_clarity * 20.0
        
        # Zaj bÃ¼ntetÃ©s (0-5)
        noise_penalty = min(noise_level * 100, 5.0)
        
        # Ã–sszes pontszÃ¡m
        total_score = snr_score + energy_score + pitch_score + clarity_score - noise_penalty
        
        return max(0.0, min(100.0, total_score))
    
    def find_best_segments(self, target_count: int = 8) -> List[Tuple[float, float, float]]:
        """Legjobb audio szegmensek megkeresÃ©se"""
        
        print(f"ğŸ” Audio analÃ­zis: {self.source_file}")
        
        # Audio betÃ¶ltÃ©s
        audio, sr = librosa.load(self.source_file, sr=None)
        total_duration = len(audio) / sr
        
        print(f"ğŸ“Š Teljes hossz: {total_duration:.1f} mÃ¡sodperc")
        print(f"ğŸ“¡ Sample rate: {sr} Hz")
        
        # Ablak paramÃ©terek
        window_duration = self.target_duration
        step_duration = 2.0  # 2 mÃ¡sodpercenkÃ©nt prÃ³bÃ¡lunk
        
        segments = []
        
        # VÃ©gigszkenneljÃ¼k az egÃ©sz fÃ¡jlt
        current_time = 0.0
        while current_time + window_duration <= total_duration:
            
            # AktuÃ¡lis szegmens kivÃ¡gÃ¡sa
            start_sample = int(current_time * sr)
            end_sample = int((current_time + window_duration) * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # MinÅ‘sÃ©g analÃ­zis
            quality_metrics = self.analyze_audio_quality(segment_audio, sr)
            
            # Szegmens hozzÃ¡adÃ¡sa ha megfelel a kritÃ©riumoknak
            if (quality_metrics['snr_db'] >= self.min_snr and 
                quality_metrics['rms_energy'] >= self.min_rms_energy):
                
                segments.append((
                    current_time, 
                    current_time + window_duration,
                    quality_metrics['quality_score']
                ))
                
                print(f"   âœ… {current_time:.1f}s-{current_time + window_duration:.1f}s: "
                      f"Q={quality_metrics['quality_score']:.1f}, "
                      f"SNR={quality_metrics['snr_db']:.1f}dB, "
                      f"RMS={quality_metrics['rms_energy']:.3f}")
            else:
                print(f"   âŒ {current_time:.1f}s-{current_time + window_duration:.1f}s: "
                      f"SNR={quality_metrics['snr_db']:.1f}dB, "
                      f"RMS={quality_metrics['rms_energy']:.3f}")
            
            current_time += step_duration
        
        # Legjobb szegmensek kivÃ¡lasztÃ¡sa
        segments.sort(key=lambda x: x[2], reverse=True)  # MinÅ‘sÃ©g szerint rendezÃ©s
        best_segments = segments[:target_count]
        
        print(f"\nğŸ¯ {len(best_segments)} legjobb szegmens kivÃ¡lasztva!")
        
        return best_segments
    
    def extract_clips(self, target_count: int = 8):
        """Klipek kivÃ¡gÃ¡sa Ã©s mentÃ©se"""
        
        # Legjobb szegmensek megkeresÃ©se
        segments = self.find_best_segments(target_count)
        
        if not segments:
            print("âŒ Nem talÃ¡lhatÃ³k megfelelÅ‘ minÅ‘sÃ©gÅ± szegmensek!")
            return
        
        # Audio betÃ¶ltÃ©s
        audio, sr = librosa.load(self.source_file, sr=None)
        
        print(f"\nğŸ¬ Klipek kivÃ¡gÃ¡sa...")
        
        extracted_clips = []
        
        for i, (start_time, end_time, quality_score) in enumerate(segments, 1):
            
            # Szegmens kivÃ¡gÃ¡sa
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # FÃ¡jlnÃ©v generÃ¡lÃ¡s
            output_filename = f"vago_premium_clip_{i:02d}_q{quality_score:.0f}.wav"
            output_path = self.output_dir / output_filename
            
            # MentÃ©s
            segment_tensor = torch.from_numpy(segment_audio).unsqueeze(0)
            torchaudio.save(str(output_path), segment_tensor, sr)
            
            extracted_clips.append(str(output_path))
            
            print(f"   ğŸ’¾ {output_filename}: {start_time:.1f}s-{end_time:.1f}s "
                  f"(Q={quality_score:.1f})")
        
        print(f"\nâœ… {len(extracted_clips)} prÃ©mium klip elkÃ©szÃ¼lt!")
        print(f"ğŸ“ MentÃ©si hely: {self.output_dir}")
        
        # Klipek Ã¶sszesÃ­tÅ‘ jelentÃ©se
        self._generate_clip_report(extracted_clips)
        
        return extracted_clips
    
    def _generate_clip_report(self, clips: List[str]):
        """Klipek minÅ‘sÃ©gi jelentÃ©sÃ©nek generÃ¡lÃ¡sa"""
        
        report = {
            'timestamp': str(np.datetime64('now')),
            'source_file': self.source_file,
            'clips': []
        }
        
        print(f"\nğŸ“Š MINÅSÃ‰GI JELENTÃ‰S")
        print("=" * 50)
        
        for clip_path in clips:
            # Audio betÃ¶ltÃ©s Ã©s analÃ­zis
            audio, sr = torchaudio.load(clip_path)
            audio_np = audio.squeeze().numpy()
            
            metrics = self.analyze_audio_quality(audio_np, sr)
            
            clip_info = {
                'filename': Path(clip_path).name,
                'path': clip_path,
                'metrics': metrics
            }
            
            report['clips'].append(clip_info)
            
            print(f"ğŸµ {Path(clip_path).name}")
            print(f"   â±ï¸ IdÅ‘tartam: {metrics['duration']:.1f}s")
            print(f"   ğŸ“¡ SNR: {metrics['snr_db']:.1f}dB")
            print(f"   âš¡ RMS energia: {metrics['rms_energy']:.3f}")
            print(f"   ğŸ¯ Pitch stabilitÃ¡s: {metrics['pitch_stability']:.2f}")
            print(f"   ğŸŒŠ SpektrÃ¡lis tisztasÃ¡g: {metrics['spectral_clarity']:.2f}")
            print(f"   ğŸ† MinÅ‘sÃ©gi pontszÃ¡m: {metrics['quality_score']:.1f}/100")
            print()
        
        # JelentÃ©s mentÃ©se
        report_path = self.output_dir / "vago_clips_quality_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ“‹ RÃ©szletes jelentÃ©s mentve: {report_path}")

def main():
    """FÅ‘program"""
    
    print("ğŸ™ï¸ VÃ¡gÃ³ IstvÃ¡n PrÃ©mium Klip KivÃ¡gÃ³")
    print("=" * 40)
    
    # EllenÅ‘rzÃ©s: lÃ©tezik-e a forrÃ¡sfÃ¡jl
    source_file = "vago_vagott.mp3"
    if not os.path.exists(source_file):
        print(f"âŒ ForrÃ¡sfÃ¡jl nem talÃ¡lhatÃ³: {source_file}")
        return
    
    # KivÃ¡gÃ³ pÃ©ldÃ¡ny
    extractor = VagoClipExtractor(source_file)
    
    # Klipek kivÃ¡gÃ¡sa
    clips = extractor.extract_clips(target_count=8)
    
    if clips:
        print(f"\nğŸ‰ SIKER! {len(clips)} prÃ©mium klip elkÃ©szÃ¼lt!")
        print("ğŸš€ Ezek hasznÃ¡lhatÃ³k ElevenLabs minÅ‘sÃ©gÅ± TTS-hez!")
    else:
        print("âŒ Nem sikerÃ¼lt megfelelÅ‘ klipeket kivÃ¡gni.")

if __name__ == "__main__":
    main()